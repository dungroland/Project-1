import streamlit as st
import torch
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification
import re
import plotly.express as px
import pandas as pd

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="BERT Sentiment Analysis", 
    page_icon="ü§ñ",
    layout="centered"
)

@st.cache_resource
def load_bert_model():
    """T·∫£i m√¥ h√¨nh BERT (cache ƒë·ªÉ tr√°nh t·∫£i l·∫°i)"""
    try:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        tokenizer = DistilBertTokenizer.from_pretrained("models/distilbert")
        model = DistilBertForSequenceClassification.from_pretrained("models/distilbert")
        model.to(device)
        model.eval()
        return tokenizer, model, device
    except:
        return None, None, None

def preprocess_text(text):
    """Ti·ªÅn x·ª≠ l√Ω vƒÉn b·∫£n"""
    text = text.lower()
    text = re.sub(r"<.*?>", " ", text)
    text = re.sub(r"[^a-zA-Z\s]", " ", text)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def predict_sentiment(text, tokenizer, model, device):
    """D·ª± ƒëo√°n c·∫£m x√∫c"""
    clean_text = preprocess_text(text)
    
    inputs = tokenizer(
        clean_text,
        return_tensors="pt",
        truncation=True,
        padding=True,
        max_length=512
    )
    
    inputs = {key: value.to(device) for key, value in inputs.items()}
    
    with torch.no_grad():
        outputs = model(**inputs)
        predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)
        predicted_class = torch.argmax(predictions, dim=-1).item()
        confidence = predictions[0][predicted_class].item()
    
    return {
        'prediction': predicted_class,
        'confidence': confidence,
        'probabilities': {
            'negative': predictions[0][0].item(),
            'positive': predictions[0][1].item()
        }
    }

# UI ch√≠nh
def main():
    # Header
    st.title("ü§ñ BERT Sentiment Analysis")
    st.markdown("**Ph√¢n lo·∫°i c·∫£m x√∫c s·ª≠ d·ª•ng DistilBERT**")
    st.markdown("---")
    
    # T·∫£i m√¥ h√¨nh
    tokenizer, model, device = load_bert_model()
    
    if tokenizer is None:
        st.error("‚ùå Kh√¥ng th·ªÉ t·∫£i m√¥ h√¨nh BERT!")
        st.info("Vui l√≤ng ch·∫°y `python src/train_bert_model.py` ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
        return
    
    # Hi·ªÉn th·ªã th√¥ng tin m√¥ h√¨nh
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Model", "DistilBERT")
    with col2:
        st.metric("Device", str(device).upper())
    with col3:
        st.metric("Max Length", "512 tokens")
    
    st.markdown("---")
    
    # Input area
    st.subheader("üìù Nh·∫≠p ƒë√°nh gi√° c·ªßa b·∫°n:")
    user_input = st.text_area(
        "ƒê√°nh gi√° phim:",
        height=150,
        placeholder="V√≠ d·ª•: This movie is absolutely fantastic! The acting was superb and the plot was engaging..."
    )
    
    # Predict button
    if st.button("üîç Ph√¢n t√≠ch c·∫£m x√∫c", type="primary"):
        if user_input.strip() == "":
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p n·ªôi dung ƒë√°nh gi√°!")
        else:
            # Hi·ªÉn th·ªã loading
            with st.spinner("ü§ñ BERT ƒëang ph√¢n t√≠ch..."):
                result = predict_sentiment(user_input, tokenizer, model, device)
            
            # Hi·ªÉn th·ªã k·∫øt qu·∫£
            st.markdown("---")
            st.subheader("üìä K·∫øt qu·∫£ ph√¢n t√≠ch:")
            
            # K·∫øt qu·∫£ ch√≠nh
            if result['prediction'] == 1:
                st.success(f"‚úÖ **POSITIVE** (T√≠ch c·ª±c)")
                st.success(f"üéØ ƒê·ªô tin c·∫≠y: **{result['confidence']:.1%}**")
            else:
                st.error(f"‚ùå **NEGATIVE** (Ti√™u c·ª±c)")
                st.error(f"üéØ ƒê·ªô tin c·∫≠y: **{result['confidence']:.1%}**")
            
            # Bi·ªÉu ƒë·ªì x√°c su·∫•t
            st.subheader("üìà Ph√¢n b·ªë x√°c su·∫•t:")
            
            prob_data = pd.DataFrame({
                'C·∫£m x√∫c': ['Negative', 'Positive'],
                'X√°c su·∫•t': [
                    result['probabilities']['negative'],
                    result['probabilities']['positive']
                ],
                'M√†u': ['#ff4444', '#44ff44']
            })
            
            fig = px.bar(
                prob_data, 
                x='C·∫£m x√∫c', 
                y='X√°c su·∫•t',
                color='C·∫£m x√∫c',
                color_discrete_map={'Negative': '#ff4444', 'Positive': '#44ff44'},
                title="X√°c su·∫•t d·ª± ƒëo√°n"
            )
            fig.update_layout(showlegend=False, height=400)
            fig.update_yaxis(tickformat='.1%')
            
            st.plotly_chart(fig, use_container_width=True)
            
            # Chi ti·∫øt s·ªë li·ªáu
            col1, col2 = st.columns(2)
            with col1:
                st.metric(
                    "Negative", 
                    f"{result['probabilities']['negative']:.1%}",
                    delta=f"{result['probabilities']['negative'] - 0.5:.1%}"
                )
            with col2:
                st.metric(
                    "Positive", 
                    f"{result['probabilities']['positive']:.1%}",
                    delta=f"{result['probabilities']['positive'] - 0.5:.1%}"
                )
    
    # Sidebar v·ªõi th√¥ng tin
    with st.sidebar:
        st.header("‚ÑπÔ∏è Th√¥ng tin")
        st.markdown("""
        **M√¥ h√¨nh:** DistilBERT
        
        **∆Øu ƒëi·ªÉm:**
        - Hi·ªÉu ng·ªØ c·∫£nh s√¢u
        - X·ª≠ l√Ω c√¢u ph·ª©c t·∫°p
        - ƒê·ªô ch√≠nh x√°c cao (~93-95%)
        
        **So v·ªõi Logistic Regression:**
        - Ch√≠nh x√°c h∆°n
        - Hi·ªÉu m·ªâa mai
        - X·ª≠ l√Ω ph·ªß ƒë·ªãnh t·ªët h∆°n
        """)
        
        st.markdown("---")
        st.markdown("**üöÄ ƒê∆∞·ª£c t·∫°o b·ªüi BERT & Streamlit**")

if __name__ == "__main__":
    main()